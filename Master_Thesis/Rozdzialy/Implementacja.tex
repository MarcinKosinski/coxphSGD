\chapter{Estymacja w modelu Coxa metodą stochastycznego spadku gradientu}

Poniższy rozdział przedstawia implementację oraz zastosowanie metody stochastycznego spadku gradientu do estymacji współczynników w modelu proporcjonalnych hazardów Coxa. Jest to główny cel pracy. Poniższe rozważania odnośnie podejścia do stosowania tej metody w tym konkretnym modelu nie są oparte na żadnej literaturze ze względu na jej brak.

W czasie powstawania pracy nawiązano jedynie nieznaczną wymianę informacji z pracownikami \textit{Harvard Laboratory for Applied Statistical Methodology \& Data Science}, dzięki której dowiedziano się że podjęte zostały kroki w kierunku stworzenia podwalin pod teorię do omawianego zagadnienia, jednak ewentualne publikacje nie zostały jeszcze dokończone. Przedsmak niedokończonej implementacji algorytmu przez pracowników wyżej wymienionego laboratorium można znaleźć w \cite{sgdpkg}.

W procesie estymacji współczynników w omawianym modelu wykorzystano pochodne cząstkowe częściowej funkcji log-wiarogodności (\ref{score})
\begin{equation*}
U_k(\beta)=\dfrac{\partial\ell_k(\beta)}{\partial\beta_k}=\sum\limits_{i=1}^{K}\Big(X_{ik}-\dfrac{\sum\limits_{l\in \mathscr{R}(t_i)}^{} X_{lk} e^{X_l'\beta}}{\sum\limits_{l\in \mathscr{R}(t_i)}^{} e^{X_l'\beta}}\Big)=\sum\limits_{i=1}^{n}Y_i\Big(X_{ik}-\dfrac{\sum\limits_{l\in \mathscr{R}(t_i)}^{} X_{lk} e^{X_l'\beta}}{\sum\limits_{l\in \mathscr{R}(t_i)}^{} e^{X_l'\beta}}\Big)=\sum\limits_{i=1}^{n}U_{k_{i}}(\beta),
\end{equation*}
(dla $Y_i = 1$, gdy obserwacja nie była cenzurowana i $Y_i = 0$, gdy obserwacja była cenzurowana; $K$ to liczba zdarzeń; $n$ to liczba obserwacji) oraz wzór (\ref{sgdrownanie}), którego wersja z adekwatnymi oznaczeniami dla powyższej funkcji wygląda następująco
\begin{equation}\label{opta}
\beta_{k_{j+1}} = \beta_{k_{j}} - \alpha_{j}U_{k_{i}}(\beta_{k_{j}}),
\end{equation}
gdzie $j$ oznacza krok algorytmu, $i$ iteruje składniki $U_{k}$, $\alpha_j$ to długość $j$-tego kroku algorytmu, zaś $U_{k}$ to $k$-ta pochodna cząstkowa gradientu $U$ oraz $\beta_{k}$ to $k$-ta współrzędna estymowanego wektora współczynników $\beta$ o rozmiarze $p$, czyli $k=1,\dots,p$. 

Własna implementacja algorytmu w języku $\mathcal{R}$ znajduje się w podrozdziale (\ref{implemento}).

\section{Porównanie z innymi modelami}

Skupiając się na informatycznym aspekcie algorytmu można stwierdzić, że idea stochastycznego spadku gradientu polega na losowaniu składnika optymalizowanej funkcji. Jednak ze statystycznego punktu widzenia, metoda stochastycznego spadku gradientu opiera się o losowanie indeksu obserwacji ze zbioru, z którego uczony jest algorytm, zanim postanowi się w jakikolwiek sposób przedstawić konkretną funkcję wiarogodności. Zatem w celu estymacji w oparciu o stochastyczny spadek gradientu w modelu Coxa, konstruując metodę, należy najpierw losować obserwacje a następnie dopiero wyznaczać formę optymalizowanej funkcji częściowej log-wiarogodności.

Dla wielu modeli opierających się o funkcje wiarogodności te dwa punkty widzenia są równoważne, jednak dla modelu Coxa nie. W przypadku modelu ADALINE sformułowanego jak w \cite{ADALINE2}, opartego na minimalizowaniu funkcji kosztu w postaci błędu najmniejszych kwadratów, w \cite{bott2} podano postać funkcji straty oraz równanie algorytmu stochastycznego spadku gradientu jak poniżej
$$Q_{adaline} = \frac{1}{2}(y-w'\varPhi(x))^2,$$ 
$$w \leftarrow w + \alpha_k(y_k-w'\varPhi(x_t))\varPhi(x_t),$$
$$\varPhi(x) \in \mathbb{R}^d, y \in \{-1,1\},$$

dla których widać, że w kolejnych krokach algorytmu $t$ wystarczy tylko jedna obserwacja $z_t=(x_t,y_t)$ aby poprawić oszacowanie parametru $w$.

W modelu proporcjonalnych hazardów Coxa jest to bardziej skomplikowane.

\section{Założenia i obserwacje}\label{zalozenia}

Dla zadanej z góry funkcji hazardu, częściowa funkcja wiarogodności odpowiada prawdopodobieństwu tego, że obserwowane zdarzenia zdarzyłyby się dokładnie w tej kolejności w jakiej się pojawiły. To prawdopodobieństwo zależy od wszystkich obserwacji w zbiorze. Niemożliwe jest wyliczenie tego poprzez obliczenie wartości funkcji częściowej wiarogodności oddzielnie dla obserwacji o numerach od 1 do 5 i oddzielnie dla obserwacji od numerach 6 do 10, a następnie przemnożeniu wyników przez siebie. Z tej przyczyny niemożliwe jest losowanie czynników optymalizowanej funkcji przy użyciu metody stochastycznego spadku gradientu do estymacji współczynników w tym modelu. \textbf{Jednak możliwe jest losowanie podzbioru obserwacji a następnie konstruowanie funkcji wiarogodności dla zaobserwowanego zredukowanego zbioru.}

Taki sposób wprowadzania obserwacji do estymacji można wykorzystać w sytuacjach, gdy mamy do czynienia z nieskończonym napływem nowych obserwacji a interesują nas oszacowania estymowanych parametrów modelu $\beta_k, k=1,\dots,p$ dla obecnie zaobserwowanych i wykorzystanych obserwacji. Proces ten ma dwie zalety: nie dość, że dla nowych obserwacji model jest w stanie na bazie obecnych oszacowań parametrów dokonać predykcji proporcji hazardów, to dodatkowo po każdej porcji obserwacji aktualizuje parametry modelu.

Ponieważ
omawiane algorytmy rozwiązują problem minimalizacji badanej funkcji, zaś
celem estymacji w modelu Coxa jest znalezienie parametrów modelu
maksymalizujących funkcję częściowej log-wiarogodności, zatem wzięcie do
minimalizacji funkcji z przeciwnym znakiem doprowadzi do wykorzystania
metod znajdujących minimum do znalezienia maksimum. 

Zakładając,~że dla~\(j\)-ego kroku
algorytmu i \(k\)-tej pochodnej cząstkowej dysponuje się zaobserwowanym podzbiorem
\(\mathcal{B}\), częściową funkcję wiarogodności dla zaobserwowanego podzbioru obserwacji \(\mathcal{B}\) wykorzystywaną do minimalizacji można zapisać następująco
\begin{equation}
-U^\mathcal{B}_k(\beta_j)=-\sum\limits_{i \in \mathcal{B}_\text{ind}}^{}U^\mathcal{B}_{k_{i}}(\beta_j)=-\sum\limits_{i \in \mathcal{B}_\text{ind}}^{}Y_i\Big(X_{ik}-\dfrac{\sum\limits_{l\in \mathscr{R}_\mathcal{B}(t_i)}^{} X_{lk} e^{X_l'\beta_j}}{\sum\limits_{l\in \mathscr{R}_\mathcal{B}(t_i)}^{} e^{X_l'\beta_j}}\Big),
\end{equation}
gdzie indeksy obserwacji należące do zbioru \(\mathcal{B}\) definiuje się jako
\(\mathcal{B}_{\text{ind}} = \{i: X_i \in \mathcal{B} \}\), zaś
\(\mathscr{R}_\mathcal{B}(t_i)\) to zbiór ryzyka dla podzbioru
\(\mathcal{B}\) w czasie \(t_i\).

Postać powyższej funkcji nasuwa pewne obserwacje. Dla danego kroku algorytmu, obecnie wykorzystywany zaobserwowany podzbiór obserwacji \(\mathcal{B}\)
\begin{itemize}
\item \textit{nie powinien składać się jedynie z obserwacji cenzurowanych}. \newline \ \newline Dla podzbioru zawierającego jedynie takie obserwacje wartość pochodnej cząstkowej funkcji log-wiarogodności jest równa zero, ze względu na czynniki $Y_i$, które dla obserwacji cenzurowanych są równe zero. Zerowa wartość pochodnej cząstkowej funkcji log-wiarogodności doprowadzi do niezmienienia się optymalizowanych parametrów we wzorze (\ref{opta}), a co za tym idzie, doprowadzi do przerwania optymalizacji.
\item \textit{nie powinien zawierać obserwacji cenzurowanych, które wszystkie mają czasy obserwacji krótsze niż najmniejszy czas obserwacji dla obserwacji niecenzurowanej}. \newline \ \newline
Obserwacje cenzurowane niosą ze sobą mniej informacji, jednak teoria analizy przeżycia stara się je maksymalnie wykorzystać, stąd uwzględnia się ich udział w zbiorze ryzyka przy estymacji fragmentów funkcji log-wiarogodności dla obserwacji niecenzurowanych. W sytuacji, gdy wszystkie obserwacje cenzurowane mają czas obserwacji krótszy niż najmniejszy czas obserwacji dla obserwacji niecenzurowanej w podzbiorze, nie dochodzi do wykorzystania obserwacji cenzurowanych w jakikolwiek sposób przy estymacji współczynników w danym kroku algorytmu.
\item \textit{nie powinien składać się jedynie z jednej obserwacji}. \newline \ \newline 
W takim przypadku wartość pochodnej cząstkowej funkcji log-wiarogodności jest również równa zero, bez względu na to czy obserwacja była cenzurowana czy nie. Zerowa wartość pochodnej cząstkowej funkcji log-wiarogodności doprowadzi do niezmienienia się optymalizowanych parametrów we wzorze (\ref{opta}), a co za tym idzie, doprowadzi do przerwania optymalizacji.
\item \textit{nie powienien zawierać tylko jednej obserwacji niecenzurowanej w zbiorze, która dodatkowo ma największy czas bycia pod obserwacją}. \newline \ \newline
W takim wypadku jedyny niezerowy czynnik w całej pochodnej cząstkowej funkcji log-wiarogodności zajdzie tylko dla obserwacji niecenzurowanej, dla której zbiór ryzyka będzie zawierał tylko nią, co da ostatecznie zerową wartość pochodnej cząstkowej optymalizowanej funkcji log-wiarogodności, co doprowadzi do przerwania optymalizacji.
\end{itemize}
\newpage
\section{Implementacja}\label{implemento}

Omówiona w tym rozdziale metoda estymacji metodą stochastycznego spadku gradientu dla modelu proporcjonalnych hazardów Coxa została zaimplementowana w języku $\mathcal{R}$ \cite{programikr} i jest dostępna w specjalnie przygotowanym pakiecie o nazwie \texttt{coxphSGD}, który można pobrać z internetu i zainstalować poleceniem
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{devtools::}\KeywordTok{install_github}\NormalTok{(}\StringTok{"MarcinKosinski/Cox-SGD"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Dokumentacja wraz z opisem argumentów w języku angielskim funkcji \texttt{coxphSGD()}, która estymuje współczynniki w modelu
proporcjonalnych hazardów Coxa metodą stochastycznego spadku gradientu, dostępna jest w Dodatku \ref{docCoxSGD}.
Starano zachować jednorodność kolejności i nazewnictwa parametrów z funkcją \texttt{coxph} z pakietu \texttt{survival} \cite{ther}, \cite{survival}.

Implementacja algorytmu estymacji w modelu Coxa metodą stochastycznego spadku gradientu opiera się na poniższym pseudo-kodzie i zakłada, że kolejne podzbiory \(\mathcal{B}\) dostarczane są jako kolejne elementy listy.
\subsubsection{Estymacja~w~modelu~Coxa~metodą~stochastycznego~spadku~gradientu}


\begin{Shaded}
\begin{Highlighting}[]
                    \CommentTok{# wstępna inicjalizacja parametrów}
\NormalTok{eps =}\StringTok{ }\FloatTok{1e-5}                               \CommentTok{# warunek stopu.}

\NormalTok{n =}\StringTok{ }\KeywordTok{length}\NormalTok{(data)                         }\CommentTok{# data jest listą ramek danych.}

\NormalTok{diff =}\StringTok{ }\NormalTok{eps +}\StringTok{ }\DecValTok{1}                           \CommentTok{# różnice w oszacowaniach parametrów}
                                         \CommentTok{# między kolejnymi krokami.}

\NormalTok{learningRates =}\StringTok{ }\NormalTok{function(x) }\DecValTok{1}\NormalTok{/x          }\CommentTok{# długości kroku algorytmu.}

\NormalTok{beta_old =}\StringTok{ }\KeywordTok{numeric}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DataTypeTok{length =} \NormalTok{k)        }\CommentTok{# punkt startowy dlugosci k,}
                                         \CommentTok{# gdzie k to liczba zmiennych}
                                         \CommentTok{# objaśniających w modelu.}

                              \CommentTok{# estymacja}
\NormalTok{i =}\StringTok{ }\DecValTok{1}                                    \CommentTok{# iterator kroku algorytmu}
\NormalTok{while(i <=}\StringTok{ }\NormalTok{n \&}\StringTok{ }\NormalTok{diff >}\StringTok{ }\NormalTok{eps) do            }\CommentTok{# do zbieżności lub wyczerpania zbiorów}
  \NormalTok{batch =}\StringTok{ }\NormalTok{data[[i]]}
  
  \NormalTok{beta_new =}\StringTok{ }\NormalTok{beta_old -}\StringTok{ }\KeywordTok{learningRates}\NormalTok{(i) *}\StringTok{ }\KeywordTok{U_Batch}\NormalTok{(batch) }
                                         \CommentTok{# U_Batch to częściowa funkcja}
                                         \CommentTok{# log-wiarogdności dla zaobserwowanego}
                                         \CommentTok{# zbioru `batch`}
  
  \NormalTok{diff =}\StringTok{ }\KeywordTok{euclidean_dist}\NormalTok{(beta_new, beta_old) }\CommentTok{# odległość euklidesowa}
  
  \NormalTok{beta_old =}\StringTok{ }\NormalTok{beta_new }
  
  \NormalTok{i =}\StringTok{ }\NormalTok{i +}\StringTok{ }\DecValTok{1}
\NormalTok{end while}
\NormalTok{return beta_new}
\end{Highlighting}
\end{Shaded}
