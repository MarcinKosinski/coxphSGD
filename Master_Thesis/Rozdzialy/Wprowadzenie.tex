\chapter*{Wprowadzenie}

W przeciągu ostatniej dekady, rozmiary danych rosły szybciej niż prędkość procesorów. W tej sytuacji możliwości statystycznych metod uczenia maszynowego stały się ograniczone bardziej przez czas obliczeń niż przez rozmiary zbiorów danych. Jak podaje \cite{bott1}, bardziej szczegółowa analiza wykazuje jakościowo różne kompromisy w przypadkach problemów uczenia maszynowego na małą i na dużą skalę. Rozwiązania kompromisowe w przypadku dużej skali danych związane są ze złożonością obliczeniową zasadniczych algorytmów optymalizacyjnych, których należy dokonywać w nietrywialny sposób. Jednym z takich rozwiązań są algorytmy optymalizacyjne oparte o stochastyczny spadek gradientu (\cite{bott1}, \cite{bott2}, \cite{widrow2}), które wykazują niesamowitą wydajność dla problemów wielkiej skali danych.

W niniejszej pracy przedstawiono algorytm estymacji współczynników w modelu Coxa metodą stochastycznego spadku gradientu. Opisany algorytm może z powodzeniem być stosowany w analizach czasu do wystąpienia zdarzenia, w których liczba zmiennych znacząco przekracza liczbę obserwacji. Przygotowana metoda estymacji współczynników z wykorzystaniem algorytmu optymalizacji metodą stochastycznego spadku gradientu może być stosowana w analizach przeżycia z dziedziny biologii molekularnej, bioinformatycznych badań przesiewowych dotyczących ekspresji genów czy w analizach opartych o mikromacierze DNA, które są szeroko stosowane w diagnostyce, leczeniu i badaniach medycznych. Zaprezentowana metoda estymacji współczynników w modelu Coxa z wykorzystaniem algorytmu optymalizacji metodą stochastycznego spadku gradientu jest metodą nową i nie spotkaną do tej pory w literaturze, jest odporna na problem współliniowości zmiennych oraz efektywnie sprawdza się w sytuacji ciągłej poprawy estymacji współczynników dla napływających danych (\textit{ang. streaming data}).

Analiza przeżycia jest starą, jednak wciąż aktywną dziedziną badań znajdującą nowe zastosowania w wielu dziedzinach, chociażby takich jak: biostatystyka, socjologia, ekonomia, demografia czy w naukach inżynieryjnych \cite{heckman}, \cite{collett}, \cite{boxst}, \cite{hosmer}. Najbardziej charakterystyczną cechą typowych danych, jakimi posługuje się w analizie przeżycia, jest obecność obiektów, w których końcowe zdarzenie nastąpiło (wówczas ma się do czynienia z obserwacjami \textit{kompletnymi}), oraz obiektów, w których to zdarzenie (jeszcze) nie nastąpiło (obserwacja \textit{ucięta}). Ta specyficzna postać danych statystycznych doprowadziła do powstania specjalnych metod stosowanych tylko w analizie czasu trwania zjawisk. Analiza przeżycia charakteryzuje relacje pomiędzy czasem do wystąpienia zdarzenia a zmiennymi objaśniającymi (\cite{kalf}, \cite{oakes}) i do niedawna ograniczona była jedynie do zastosowań oraz analiz opartych na garści zmiennych objaśniających przy maksymalnie kilku tysiącach obserwacji. Jednak ostatnie dokonania i postępy w obszarach rozwoju technik pozyskiwania danych i ułatwiony, wraz z postępem cywilizacyjnym, dostęp do większej mocy obliczeniowej spowodowały wzmożenie zainteresowania danych z potencjalnie setkami tysięcy, a nawet milionami zmiennych. Przykładem mogą być nowe technologie w genomice produkujące wielowymiarowe mikromacierze ekspresji genów, w których liczba zmiennych prognozujących przeżycie może sięgać rozmiarom rzędu $10^5$ lub nawet większym. Inne przykłady zastosowań analizy przeżycia dla danych wielkiej skali to badania monitorowania medycznych zdarzeń niepożądanych, wielopomiarowe i rozłożone w czasie badania kliniczne czy analizy eksploracyjne (\textit{ang. data mining}) danych biznesowych.

Praca przedstawia podejście do analizy przeżycia z wykorzystaniem modelu proporcjonalnych hazardów Coxa \cite{cox}. Jak podaje \cite{assel}, model proporcjonalnych hazardów Coxa jest jednym z najszerzej stosowanych modeli w onkologicznych publikacjach naukowych, ale także jedną z najmniej rozumianych metod statystycznych. Wynika to z łatwego dostępu do pakietów statystycznych zawierających programy do analizy przeżyć, modeli regresji i analiz wielowariantowych, ale prawie nigdy nie zawierających dobrego opisu podstawowych zasad działania modelu Coxa. Dostarczają one wyłącznie instrukcje, jak wprowadzić dane i uruchomić odpowiednie procedury w celu uzyskania wyniku. Poniższa praca zawiera pełny opis metodologii modelu proporcjonalnych hazardów Coxa, w tym wyjaśnienie najważniejszych pojęć. W odróżnieniu do modeli parametrycznych analizy czasu do wystąpienia zdarzenia (\cite{klein}, \cite{collett}, \cite{hosmer}), model Coxa oferuje większą elastyczność dzięki swojej semi-parametrycznej naturze, dając jednocześnie  współczynniki regresji, które są łatwo interpretowalne. Zazwyczaj współczynniki w modelu Coxa otrzymuje się dzięki maksymalizacji częściowej funkcji log-wiarogodności modelu. Jednak w sytuacji przekleństwa wymiarowości standardowe metody estymacji metodami spadku gradientu takimi jak metoda Cauchy'ego czy Raphsona-Newtona zawodzą z racji na zbyt złożone i długotrwałe obliczenia. Dodatkowy problem stanowi współliniowość zmiennych, co utrudnia utrzymanie numerycznej stabilności algorytmów optymalizacyjnych. W literaturze zaproponowano wiele rozwiązań problemu współliniowości poprzez dodanie do funkcji częściowej log-wiargodności dodatkowego parametru związanego z karą dla modelu za zbyt dużą liczbę zmiennych w trakcie estymacji \cite{parkm}, \cite{sohn}, \cite{goemann}. Taka metoda, zwana regularyzacją, prowadzi do zminimalizowana liczby zmiennych w modelu poprzez wyzerowanie współczynników dla nieistotnych statystycznie zmiennych. Jednak powyższe rozwiązania znalazły zastosowania jedynie dla zbiorów danych małej skali. Takie podejście nie przeniosło się na zbiory dużej skali ze względu na występowanie w algorytmie spadku gradientu Raphsona-Newtona kosztownych kroków obliczeniowych algorytmu wymagających odwracania wielkich macierzy, co numerycznie nie jest proste. Ponadto, jak opisuje \cite{mital} możliwe obejścia i przybliżenia często prowadzą do dużych różnic współczynników i słabego oszacowania predykcyjnej dokładności czy złego dopasowania modelu. Rozwój badań nad danym problemem (\cite{KIMKIM}) doprowadził do powstania metod wykorzystujących jedynie pierwszą pochodną częściowej penalizowanej (z parametrem regularyzacji) funkcji log-wiarogodności w modelu Coxa (\cite{sohn} w opraciu o \cite{KIM}, rozszerzenie podejścia w \cite{mital}), które byłyby odporne na problemy danych dużej skali, gdyż nie wymagały obliczania i odwracania macierzy Hesjanu. 

Podejścia te trudno wykorzystać w sytuacjach napływu danych, gdy nie dysponuje się wszystkimi obserwacji jednocześnie, a zachodzi potrzeba wykorzystania tych już zaobserwowanych do estymacji współczynników oraz rodzi się okazja do poprawy współczynników z każdą nową obserwacją \cite{bottDOD}. Dlatego w warunkach napływu danych możliwym rozwiązaniem jest zastosowanie algorytmu optymalizacji metodą stochastycznego spadku gradientu, który w wielu modelach do estymacji współczynników wymaga jedynie jednej obserwacji. W modelu proporcjonalnych hazardów Coxa wykorzystanie metody stochastycznego spadku gradientu jest możliwe dla zaobserwowanych kilku obserwacji, z racji na postać częściowej funkcji log-wiarogodności, której kolejne składniki są zależne od innych obserwacji. Szerokie badania w celu wykorzystania metody stochastycznego spadku gradientu do estymacji w modelu proporcjonalnych hazardów Coxa prowadzą pracownicy \textit{Harvard Laboratory for Applied Statistical Methodology \& Data Science}, którzy zaproponowali podejście uwikłanego (\textit{ang. implicit}) stochastycznego spadku gradientu, który dla danego kroku optymalizacji wykorzystuje w równaniu na nowe współczynniki jeszcze nie wyliczone nowe współczynniki (\cite{toulis} w publikacji).  

 W owej pracy zaprezentowano prostsze podejście wykorzystania w estymacji współczynników w modelu proporcjonalnych hazardów Coxa estymacji opartej o stochastyczny spadek gradientu do zaobserwowanych podzbiorów obserwacji. Takie podejście pozwala na efektywne osiągnięcie zbieżności algorytmu optymalizacji, w sytuacji napływających danych o dużym rozmiarze zmiennych objaśniających, przy jednoczesnej odporności na współliniowość zmiennych oraz z profitem poprawy oszacowań współczynników modelu po każdym zaobserwowanym podzbiorze obserwacji.

Rozdział \ref{chap1} pracy opisuje metodę największej wiarogodności i jej matematyczne własności, dzięki której możliwe jest wyznaczanie estymatorów największej wiarogodności. Rozdział uzasadnia również poprawność wykorzystywania estymatorów uzyskanych dzięki metodzie największej wiarogodności poprzez udowodnienie ich własności takich jak: asymptotyczna normalność, asymptotyczna nieobciążoność oraz zgodność. 

Rozdział \ref{chap2} poświęcony jest modelowi proporcjonalnych hazardów Coxa. Przedstawione są podstawowe terminy i definicje analizy przeżycia oraz sformułowany jest model Coxa. Rozdział opisuje niezbędne założenia w modelu Coxa oraz prezentuje metodę analitycznej estymacji w oparciu o szeroko opisaną częściową funkcję log-wiarogodności modelu i estymatory największej wiarogodności. Rozdział \ref{chap2} kończy się opisaniem metody generowania danych dla modelu Coxa oraz implementacją funkcji generującej dane do analizy przeżycia pochodzące z rozkładu Weibulla. 

W rozdziale \ref{numPAJ} scharakteryzowany jest algorytm numerycznej optymalizacji metodą stochastycznego spadku gradientu. Rozdział ukazuje wady i zalety stochastycznego spadku gradientu oraz przedstawia różnice między tym algorytmem a algorytmami spadku gradientu rzędu I (Cauchy'ego) oraz spadku gradientu rzędu II (Raphsona-Newtona). Rozdział \ref{numPAJ} zwieńczony jest implementacją trzech omówionych algorytmów numerycznej optymalizacji dla problemu estymacji przy pomocy metody największej wiarogodności dla modelu regresji logistycznej. Implementacja posłużyła do przeprowadzenia symulacji, dzięki którym możliwe było graficzne ukazanie różnic w ścieżkach zbiegania do optimum między algorytmami spadku gradientu i algorytmem stochastycznego spadku gradientu. 

Rozdział \ref{rozdz4} przedstawia matematyczne podstawy zastosowania algorytmu numerycznej optymalizacji metodą stochastycznego spadku gradientu do estymacji współczynników w modelu proporcjonalnych hazardów Coxa w oparciu o analityczną metodę estymacji największej wiarogodności zastosowaną do częściowej funkcji log-wiarogodności skonstruowaną jedynie dla obecnie zaobserwowanego podzbioru danych w sytuacji napływu danych. Opisane są warunki konieczne, jakie musi spełniać zaobserwowany podzbiór danych, aby nie przerwać procesu optymalizacji częściowej funkcji log-wiarogodności. Rozdział prezentuje implementację opisanej metody w pseudo kodzie oraz podaje implementację wyrażoną w języku $\mathcal{R}$ \cite{programikr}, \cite{biecek1}. Rozdział \ref{rozdz4} kończy się przeprowadzeniem symulacji mających na celu wygenerowanie danych z modelu Coxa, dzięki wykorzystaniu implementacji z rozdziału \ref{chap2}, oraz na zastosowaniu przygotowanego algorytmu do wyestymowania współczynników w modelu Coxa dzięki użyciu metody stochastycznego spadku gradientu. Wyniki symulacji przedstawiono na wykresach i porównano kroki algorytmów dla różnych wielkości zaobserwowanych podzbiorów obserwacji wykorzystanych do jednego kroku algorytmu optymalizacji. 

Praca kończy się rozdziałem \ref{chap5}, w którym metoda estymacji w modelu Coxa proporcjonalnych hazardów z wykorzystaniem stochastycznego spadku gradientu zastosowana jest do analizy na prawdziwych danych pochodzących z badania \textit{The Cancer Genome Atlas} (TCGA). Rozdział referuje genetyczne podstawy nowotworzenia oraz opisuje dane z TCGA wraz z procesem ich pozyskania i przetwarzania (\cite{kosa1}, \cite{kosa2}, \cite{kosa3}). W analizie w rozdziale \ref{chap5} sprawdzany jest wpływ wystąpienia mutacji w danym genie na czas do wystąpienia zdarzenia niepożądanego jakim jest śmierć pacjenta w wyniku choroby nowotworowej.

W pracy zostały przedstawione kody pakietu $\mathcal{R}$, użyte do symulacji oraz analizy przeżycia, których zestawienie i podsumowanie można znaleźć w Dodatku \ref{docCoxSGD}. Implementacja estymacji w modelu Coxa proporcjonalnych hazardów metodą stochastycznego spadku gradientu oraz funkcje symulujące dane i generujące wykresy porównujące trajektoria zbieżności algorytmu zostały opakowane w pakiet do $\mathcal{R}$ o nazwie \texttt{coxSGD} (\cite{kosa0}) oraz umieszczone w internecie pod adresem \texttt{https://github.com/MarcinKosinski/coxphSGD}. Dokumentacja pakietu w języku angielskim została przedstawiona w Dodatku \ref{docCoxSGD}.

\chapter*{Podstawy modelu statystycznego}

W pracy zakłada się znajomość podstaw statystyki matematycznej. Aby ujednolicić oznaczenia, w niniejszym rozdziale wprowadzona została klasyczna terminologia oparta~o~\cite{niemiro}.

\begin{definition}
\textbf{Model statystyczny} określamy przez podanie rodziny $\{ \mathbb P_{\theta}:\theta\in\Theta\} $ rozkładów prawdopodobieństwa na przestrzeni próbkowej $\Omega$ oraz zmiennej losowej $X : \Omega \rightarrow \mathcal{X}$, którą traktujemy jako obserwację. Zbiór $\mathcal{X}$ nazywamy przestrzenią obserwacji, zaś $\Theta$ nazywamy przestrzenią parametrów. \\
\end{definition}
Symbol $\theta$ jest nieznanym parametrem opisującym rozkład badanego zjawiska. Może być jednowymiarowy lub wielowymiarowy. Determinując opis zjawiska poprzez podanie parametru $\theta$, jednoznacznie wyznaczany jest rozkład rozważanego zjawiska spośród całej rodziny rozkładów prawdopodobieństwa $\{ \mathbb P_{\theta}:\theta\in\Theta\}$, co umożliwia określenie prawdziwości tezy.
\par
Zakłada się, że przestrzeń próbkowa $\Omega$ jest wyposażona w $\sigma$-ciało $\mathcal{F}$. Wtedy:
\begin{definition}
\textbf{Przestrzenią statystyczną} nazywa się trójkę $(\mathcal{X},\mathcal{F},\{\mathbb P_{\theta}:\theta\in\Theta\})$.
\end{definition}
Wprowadzenie $\sigma$-ciała $\mathcal{F}$ sprawia, że przestrzeń statystyczna staje się przestrzenią mierzalną, a więc można na niej określić rodzinę $\{ \mathbb P_{\theta}:\theta\in\Theta\} $, dzięki której da się ustalić prawdopodobieństwa zajścia wszystkich zjawisk w rozważanej teorii.

W celu budowania niezbędnych pojęć potrzebna jest również definicja losowej próby statystycznej, zazwyczaj nazywanej \textit{próbką}.

\begin{definition}
 \textbf{Losową próba statystyczną} nazywamy zbiór obserwacji statystycznych wylosowanych z populacji, które są realizacjami ciągu zmiennych losowych o rozkładzie takim jak rozkład populacji.
 \end{definition}
