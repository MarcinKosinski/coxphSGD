\chapter{Numeryczne metody estymacji}

Przez \textbf{numerykę} rozumie się dziedzinę matematyki
zajmującą się rozwiązywaniem przybliżonych zagadnień algebraicznych. Odkąd zjawiska przyrodnicze zaczęto opisywać przy użyciu formalizmu matematycznego,
pojawiła się potrzeba rozwiązywania zadań analizy matematycznej czy algebry. Dopóki były
one nieskomplikowane, dawały się rozwiązywać analitycznie, tzn. z użyciem pewnych
przekształceń algebraicznych prowadzących do otrzymywania rozwiązań ścisłych danych
problemów. Z czasem jednak, przy powstawaniu coraz to bardziej skomplikowanych teorii
opisujących zjawiska, problemy te stawały się na tyle złożone, iż ich rozwiązywanie ścisłe
było albo bardzo czasochłonne albo też zgoła niemożliwe. Numeryka pozwalała znajdywać
przybliżone rozwiązania z żądaną dokładnością. Ich podstawową zaletą była ogólność tak
formułowanych algorytmów, tzn. w ramach danego zagadnienia nie miało znaczenia czy było
ono proste czy też bardzo skomplikowane (najwyżej wiązało się z większym nakładem pracy
obliczeniowej). Natomiast wadą była czasochłonność. Stąd prawdziwy renesans metod
numerycznych nastąpił wraz z powszechnym użyciem w pracy naukowej maszyn cyfrowych,
a w szczególności mikrokomputerów \cite{milewski}. Dziś dziesiątki żmudnych dla człowieka operacji
arytmetycznych wykonuje komputer, jednak złożoność obliczeniowa algorytmów uczących i modeli statystycznych stała się krytycznym czynnikiem ograniczającym w sytuacjach, gdy rozważane są duże zbiory danych. Te ograniczenia spowodowały, że w uczeniu maszynowym i modelowaniu statystycznym wielkiej skali zaczęto wykorzystywać algorytmy \textbf{stochastycznego spadku gradientu}. W poniższym rozdziale przedstawione są klasyczne algorytmy spadku wzdłuż gradientu Cauchy'ego oraz Raphsona-Newtona. Następnie omówiony jest algorytm stochastycznego spadku wzdłuż gradientu, którego wykorzystanie do estymacji współczynników w modelu Coxa jest kluczowym celem tej pracy. Algorytm stochastycznego spadku gradientu to metoda optymalizacji wzdłuż spadku gradientu wykorzystywana w sytuacjach, gdy rozważaną funkcję można zapisać jako sumę różniczkowalnych składników. Ponadto przedstawiono również zalety algorytmów stochastycznego spadku gradientu, które przemawiają za atrakcyjnością i popularnością tego typu rozwiązania. Ostatecznie przedyskutowano asymptotyczną efektywność estymatorów uzyskanych dzięki jednemu przejściu po zbiorze, zwanym \textit{epoką}. Definicje i pojęcia w tym rozdziale pochodzą z~\cite{bott1},~\cite{bott2},~\cite{kotlowski}~i~\cite{fortuna}.

\newpage
\section{Algorytmy spadku wzdłuż gradientu}

Poniższy rozdział przedstawia popularne iteracyjne algorytmy wyznaczania przybliżonej wartości miejsca zerowego funkcji oraz rozważaną w pracy metodę stochastycznego spadku gradientu. Szukanie miejsc zerowych funkcji jest przydatne w problemach optymalizacyjnych, gdy celem jest znalezienie pierwiastka pochodnych badanej funkcji. Dodatkowo takie algorytmy wykorzystywane są do rozwiązywania (nieliniowych) układów równań. Metody iteracyjne składają się zazwyczaj z $k$ kroków bądź są zatrzymywane, gdy osiągnięty zostanie warunek stopu, czyli gdy odległość pomiędzy kolejnymi przybliżeniami jest dość mała $\parallel w_{k+1}-w_k\parallel < \epsilon$ lub wartość gradientu funkcji w wyznaczonym punkcie jest bliska wektorowymi zerowemu $\parallel \nabla_Q(\mathbf{w_k}) \parallel \leqslant \epsilon$ (test stacjonarności), gdzie $\epsilon$ to zadana z góry precyzja.
Metoda stochastycznego spadku wzdłuż gradientu zakłada, że minimalizowaną funkcję $Q(w)$ można przedstawić jako różniczkowalną sumę jej składników $Q(w) = \sum_{i=1}^{n}Q_i(w)$. W~poniższych algorytmach $\alpha_k$ oznacza długość kroku algorytmu.
\begin{center}
\textbf{Metoda spadku wzdłuż gradientu I (Cauchy’ego)}
\end{center}
Minimalizacja funkcji $Q(w)$:
\begin{itemize}
\item Zaczynamy od wybranego rozwiązania startowego, np. $w_{0} = 0$.
\item Dla $k = 1, 2, \dots$ aż do zbieżności
	\begin{itemize}
	\item Wyznaczamy gradient w punkcie $w_{k-1}, \nabla_{Q}(w_{k-1})$.
	\item Robimy krok wzdłuż negatywnego gradientu: $$w_{k} = w_{k-1} - \alpha_{k}\nabla_{Q}(w_{k-1}). $$
	\end{itemize}
\end{itemize}

\begin{center}
\textbf{Metoda spadku wzdłuż gradientu II (Newtona-Raphsona)}
\end{center}
Minimalizacja funkcji $Q(w)$:
\begin{itemize}
\item Zaczynamy od wybranego rozwiązania startowego, np. $w_{0} = 0$.
\item Dla $k = 1, 2, \dots$ aż do zbieżności
	\begin{itemize}
	\item Wyznaczamy gradient w punkcie $w_{k-1}, \nabla_{Q}(w_{k-1})$ i odwrotność Hesjanu $(D_{Q}^{2}(w_{k-1}))^{-1}$.
	\item Robimy krok wzdłuż negatywnego gradientu z zadanym krokiem przez Hesjan: $$w_{k} = w_{k-1} - (D_{Q}^{2}(w_{k-1}))^{-1}\nabla_{Q}(w_{k-1}). $$
	\end{itemize}
\end{itemize}
\begin{center}
\textbf{Metoda stochastycznego spadku wzdłuż gradientu I}
\end{center}
Minimalizacja funkcji $Q(w)$:
\begin{itemize}
\item Zaczynamy od wybranego rozwiązania startowego, np. $w_{0} = 0$.
\item Dla $k = 1, 2, \dots$ aż do zbieżności
	\begin{itemize}
	\item Wylosuj $i \in \{1,\dots,n\}$
	\item Wyznaczamy gradient funkcji $Q_{i}$ w punkcie $w_{k-1}, \nabla_{Q_{i}}(w_{k-1})$.
	\item Robimy krok wzdłuż negatywnego gradientu: $$w_{k} = w_{k-1} - \alpha_{k}\nabla_{Q_{i}}(w_{k-1}).$$
	\end{itemize}
\end{itemize}

\section{Algorytm stochastycznego spadku wzdłuż gradientu I}\label{SGD}
Stochastyczny spadek gradientu to popularny algorytm wykorzystywany do estymacji współczynników w szerokiej gamie modeli uczenia maszynowego takich jak maszyny wektorów podpierających (\textit{ang. Support Vector Machines}), regresja logistyczna czy modele graficzne~\cite{finkel}. W~połączeniu z algorytmem propagacji wstecznej jest standardowym algorytmem w~trenowaniu sztucznych sieci neuronowych. Algorytm stochastycznego spadku gradientu był używany już od 1960 przy estymacji współczynników w modelu regresji liniowej, oryginalnie znanym pod nazwą \textit{ADALINE} \cite{ADALINE}. Kolejnym znanym popularnym algorytmem wykorzystującym stochastyczny spadek gradientu jest filtr adaptacyjny najmniejszych średnich kwadratów \cite{widrow2} (\textit{ang.~least mean squares (LMS) adaptive filter}), który również został wynaleziony w 1960 przez Bernarda Widrowa, który jest także twórcą \textit{ADALINE}.

Idea algorytmu stochastycznego spadku gradientu jest następująca: zamiast obliczać gradient na całej funkcji $L$, w danym kroku oblicz
gradient tylko na pojedynczym elemencie $\ell_{i}$. Nazwa \textit{stochastyczny} bierze się stąd, iż oryginalnie wybiera
się element $\ell_{i}$ losowo. W praktyce zwykle przechodzi się po całym zbiorze danych w losowej kolejności lub, o ile to możliwe, w~kolejności chronologicznej obserwacji.



\subsection{Właściwości stochastycznego spadku wzdłuż gradientu}

Zbieżność algorytmu stochastycznego spadku gradientu była badana szeroko badana w literaturze aproksymacji stochastycznych. Aby uzyskać zbieżność zazwyczaj wymaga się aby ciąg kroków algorytmu $\alpha_k$ był malejący i spełniał poniższe warunki $\sum\nolimits_k \alpha_k = \infty$ oraz $\sum\nolimits_k \alpha_k^2 < \infty$ \cite{bott1}.
Twierdzenie Robbinsa-Siegmunda \cite{robbins} przy łagodnych warunkach zapewnia zbieżność prawie na pewno \cite{bottDOD}, nawet w sytuacjach gdy optymalizowana funkcja nie jest wszędzie różniczkowalna.

Prędkość zbieżności sotchastycznego spadku gradientu jest w rzeczywistości ograniczana przez \textcolor{red}{zaszumioną (\textit{ang. noisy})} aproksymacje prawdziwego gradientu. Gdy kroki algorytmu
maleją zbyt wolno, wariancja estymatorów parametrów $w_k$ maleje równie wolno. Gdy kroki algorytmu maleją
zbyt szybko, oczekiwane estymatory parametrów $w_k$ potrzebują więcej czasu by osiągnąć optimum \cite{bott1}. Pod pewnymi warunkami regularności \cite{murata}, najlepsza prędkość zbieżności jest uzyskana dla kroków algorytmu $\alpha_k\sim k^{-1}$.

Jak wykazano w \cite{dennis} pod pewnymi odpowiednimi warunkami regularności, gdy zainicjowany współczynnik początkowy $w_0$ jest wystarczająco blisko optimum i krok algorytmu jest odpowiednio mały, algorytm stochastycznego spadku gradientu osiąga liniową zbieżność. Oznacza to, iż przy spełnieniu założeń metody, odległości pomiędzy kolejnymi przybliżeniami a minimum funkcji $\mathbf{w^{\ast}}$ maleją liniowo: $\parallel \mathbf{w^{\ast}} - \mathbf{w_{k+1}} \parallel \leqslant c \parallel \mathbf{w^{\ast}} - \mathbf{w_k} \parallel$. Zbieżność wymaga często przejścia parokrotnie po całym
zbiorze danych. Zwykle nie losuje się obserwacji, ale przechodzi się po zbiorze
danych w losowej kolejności. Dodatkowo wady i zalety algorytmu wylistowane są poniżej. Zalety~zdecydowanie przewyższają~wady.

\subsubsection{Zalety}
\begin{itemize}
\item \textcolor{orange}{Szybkość}: obliczenie gradientu wymaga wzięcia tylko jednej
obserwacji.
\item \textcolor{orange}{Skalowalność}: cały zbiór danych nie musi nawet znajdować się
w pamięci operacyjnej.
\item \textcolor{orange}{Prostota}: gradient funkcji  $Q_{i}$ daje bardzo prosty wzór na
modyfikacje wag.
\end{itemize}

\subsubsection{Wady}
\begin{itemize}
\item \textcolor{orange}{Wolna zbieżność}: czasem gradient stochastyczny zbiega wolno
i wymaga wielu iteracji po zbiorze uczącym.
\item \textcolor{orange}{Problem z ustaleniem długości kroku $k$}: wyznaczenie $k$
przez przeszukiwanie liniowe nie przynosi dobrych rezultatów,
ponieważ optymalizujemy oryginalnej funkcji $Q$ tylko jej jeden
składnik $Q_{i}$.
\end{itemize}

\section{Ewentualne obrazki obrazujące/porównujące algorytmy}

\textcolor{red}{Coś tego typu porównujące może algorytm Cauchy'ego, Raphsona-Newtona i SGD?}

\begin{figure}[h]
\includegraphics[width=\textwidth, height=15cm]{Obrazki/gd}
\caption{Porównanie algorytmów spadku gradientu.}
\end{figure}

